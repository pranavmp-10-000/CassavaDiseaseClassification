{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "cassavaclassification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mP00kRXTxyDA",
        "NuIBqEi3Xqnz"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavmp-10-000/CassavaDiseaseClassification/blob/main/cassavaclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMeLEZr6iGWd"
      },
      "source": [
        "# Kaggle Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arK14FWEx4jf",
        "outputId": "c9200663-0821-43b2-9ee4-ed9b30f4f4d9"
      },
      "source": [
        "! pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.11.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL0DiWJRyDXg"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4Uy0Ai7yGX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a734ce27-8d3a-4a2a-d20b-d6cd41f0a96d"
      },
      "source": [
        " ! mkdir ~/.kaggle\n",
        " ! cp kaggle.json ~/.kaggle/\n",
        " ! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0mFgjiozD8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db3cb66-c795-470a-ec4b-4c3bdbf467e1"
      },
      "source": [
        "!mkdir /content/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEKMXt9f0Vw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71073073-e833-4cf3-c6dd-533b088263af"
      },
      "source": [
        "!kaggle competitions files cassava-leaf-disease-classification"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "name                                    size  creationDate         \n",
            "-------------------------------------  -----  -------------------  \n",
            "train_tfrecords/ld_train07-1338.tfrec  216MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train00-1338.tfrec  217MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train13-1338.tfrec  217MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train09-1338.tfrec  217MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train12-1338.tfrec  216MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train06-1338.tfrec  216MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train01-1338.tfrec  215MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train04-1338.tfrec  216MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train02-1338.tfrec  216MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train15-1327.tfrec  214MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train10-1338.tfrec  217MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train05-1338.tfrec  214MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train08-1338.tfrec  217MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train03-1338.tfrec  217MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train14-1338.tfrec  215MB  2020-11-25 16:32:50  \n",
            "train_tfrecords/ld_train11-1338.tfrec  218MB  2020-11-25 16:32:50  \n",
            "test_tfrecords/ld_test00-1.tfrec       191KB  2020-11-25 16:32:50  \n",
            "test_images/2216849948.jpg             141KB  2020-11-25 16:32:50  \n",
            "train_images/1002088496.jpg            131KB  2020-11-25 16:32:50  \n",
            "train_images/1003888281.jpg            110KB  2020-11-25 16:32:50  \n",
            "train_images/1000837476.jpg            104KB  2020-11-25 16:32:50  \n",
            "train_images/100204014.jpg             170KB  2020-11-25 16:32:50  \n",
            "train_images/1000723321.jpg            119KB  2020-11-25 16:32:50  \n",
            "train_images/1000201771.jpg            158KB  2020-11-25 16:32:50  \n",
            "train_images/1000015157.jpg            136KB  2020-11-25 16:32:50  \n",
            "train_images/1001749118.jpg            135KB  2020-11-25 16:32:50  \n",
            "train_images/1003298598.jpg            142KB  2020-11-25 16:32:50  \n",
            "train_images/1001742395.jpg            100KB  2020-11-25 16:32:50  \n",
            "train_images/1003442061.jpg            101KB  2020-11-25 16:32:50  \n",
            "train_images/1000910826.jpg            100KB  2020-11-25 16:32:50  \n",
            "train_images/1002394761.jpg            101KB  2020-11-25 16:32:50  \n",
            "train_images/1001320321.jpg             82KB  2020-11-25 16:32:50  \n",
            "train_images/1000812911.jpg             79KB  2020-11-25 16:32:50  \n",
            "train_images/1003218714.jpg            127KB  2020-11-25 16:32:50  \n",
            "train_images/1003987001.jpg            101KB  2020-11-25 16:32:50  \n",
            "train_images/1002255315.jpg            150KB  2020-11-25 16:32:50  \n",
            "train_images/1001723730.jpg             84KB  2020-11-25 16:32:50  \n",
            "train_images/100042118.jpg              73KB  2020-11-25 16:32:50  \n",
            "train.csv                              350KB  2020-11-25 16:32:50  \n",
            "label_num_to_disease_map.json           172B  2020-11-25 16:32:50  \n",
            "sample_submission.csv                    32B  2020-11-25 16:32:50  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aibAxjqiyMAe",
        "outputId": "b1dfbc66-4ea1-4469-a839-e4d97cb916e9"
      },
      "source": [
        "!kaggle competitions download -c cassava-leaf-disease-classification -p /content/data -f /train.csv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "404 - Not Found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKczwJ-PxyC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6d04e46-be94-43d0-e964-7238c855120e"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import glob\n",
        "from functools import partial\n",
        "import IPython.display as display\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/data'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_615hszxDc-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a087f9-fb9a-4193-d98f-f4e341bec633"
      },
      "source": [
        "!unzip data/\\*.zip -d /content/data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open data/*.zip, data/*.zip.zip or data/*.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX8zLKUQxyC_",
        "outputId": "342a172c-3151-4566-e3b0-8b936f1a9705"
      },
      "source": [
        "try: # detect TPUs\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except ValueError: # no TPU found, detect GPUs\n",
        "    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
        "\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.191.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.48.191.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of accelerators:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "727g5_PameAY"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "GCS_PATH = 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc'\n",
        "IMAGE_SIZE = [512,512]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "knLpgOBBxyC_",
        "outputId": "7b9b8dd9-b5f1-45fc-a4e1-aba637011811"
      },
      "source": [
        "train_records = pd.read_csv('/content/data/train.csv')\n",
        "#test_records = pd.read_csv('../input/cassava-leaf-disease-classification/test.csv')\n",
        "train_records.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000015157.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000201771.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100042118.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000723321.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000812911.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_id  label\n",
              "0  1000015157.jpg      0\n",
              "1  1000201771.jpg      3\n",
              "2   100042118.jpg      1\n",
              "3  1000723321.jpg      1\n",
              "4  1000812911.jpg      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KVDv85gKaet"
      },
      "source": [
        "data_value_c = pd.DataFrame(train_records['label'].value_counts())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "9CwtqWbZldwq",
        "outputId": "8a7975e0-cff8-4eee-aea0-31472fea0ec3"
      },
      "source": [
        "sns.barplot(data_value_c.index,data_value_c.label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8590a19320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPIhVmwszmrz"
      },
      "source": [
        "class_weights = train_records.groupby(['label']).count()\n",
        "class_weights['image_id'] = class_weights.image_id/train_records.shape[0]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE4Uc2s80Fil"
      },
      "source": [
        "cl_w = class_weights.image_id.to_dict()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPVGrrxhxyDA"
      },
      "source": [
        "TRAIN_DIRECTORY = '/content/data/'\n",
        "#TEST_DIRECTORY = '../input/cassava-leaf-disease-classification/test_images/'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjn98WujxyDA"
      },
      "source": [
        "def submit_gen(model,classes,dataset_path,col='image_id'):\n",
        "  test_data = os.listdir(dataset_path)\n",
        "  pred_array=[]\n",
        "  for i in test_data:\n",
        "    img = tf.keras.preprocessing.image.load_img(\n",
        "        dataset_path+i,target_size=(512,512))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "    prediction = np.squeeze(model.predict(img_array))\n",
        "    name_c = classes[np.argmax(prediction)]\n",
        "    pred_array.append(name_c)\n",
        "  return pred_array,test_data"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TstP7vTC3MXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99211faa-487d-4262-cf85-440a8f8b8447"
      },
      "source": [
        "gs_filenames = tf.io.gfile.glob(GCS_PATH + \"/train_tfrecords/*.tfrec\")\n",
        "gs_filenames"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train00-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train01-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train02-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train03-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train04-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train05-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train06-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train07-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train08-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train09-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train10-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train11-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train12-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train13-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train14-1338.tfrec',\n",
              " 'gs://kds-8ce61d4a373ab9f3d5a795bc43d1fb6e4a1b250fcc1ef4954a9f9afc/train_tfrecords/ld_train15-1327.tfrec']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfMwErjgEJmU"
      },
      "source": [
        "split_ind = int(0.9 * len(gs_filenames))\n",
        "TRAINING_FILENAMES, VALID_FILENAMES = gs_filenames[:split_ind], gs_filenames[split_ind:]\n",
        "dataset = tf.data.TFRecordDataset(filenames=TRAINING_FILENAMES)\n",
        "val_dataset = tf.data.TFRecordDataset(filenames=VALID_FILENAMES)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFR5Gg_ALmpE"
      },
      "source": [
        "def augment(image):\n",
        "  #image = tf.keras.preprocessing.image.(image,channels=3)\n",
        "  image = tf.image.random_flip_left_right(image,seed=2)\n",
        "  image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  #image = tf.reshape(image,(3,512,512))\n",
        "  image = tf.keras.preprocessing.image.random_rotation(image,35,row_axis=1 ,col_axis=0, channel_axis=2)\n",
        "  image = tf.keras.preprocessing.image.random_shear(image,5,row_axis=1 ,col_axis=0, channel_axis=2)\n",
        "  image = tf.keras.preprocessing.image.random_shift(image,0.1,0.1,row_axis=1 ,col_axis=0, channel_axis=2)\n",
        "  #image = tf.reshape(image,(*IMAGE_SIZE,3))\n",
        "  image = tf.keras.preprocessing.image.array_to_img(image)\n",
        "  return image"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "677I809zUioo"
      },
      "source": [
        "image_feature_description = {\n",
        "    'image': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_name': tf.io.FixedLenFeature([], tf.string),\n",
        "    'target': tf.io.FixedLenFeature([], tf.int64),\n",
        "    \n",
        "}\n",
        "\n",
        "def _parse_image_function(example_proto):\n",
        "  # Parse the input tf.train.Example proto using the dictionary above.\n",
        "  example = tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "  image = tf.image.decode_jpeg(example['image'],channels=3)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = tf.reshape(image,[*IMAGE_SIZE,3])\n",
        "  label = tf.cast(example[\"target\"], tf.int32)\n",
        "  return image,label"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QdqqDxOUwAi"
      },
      "source": [
        "parsed_image_dataset = dataset.map(partial( _parse_image_function),num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmVBm944mD8w"
      },
      "source": [
        "val_image_dataset = val_dataset.map(partial( _parse_image_function),num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5aNog8bM0OW",
        "outputId": "f055de7b-8493-43b8-ce45-7a3fd86e364d"
      },
      "source": [
        "for i,x in parsed_image_dataset.take(1):\n",
        "  print(i.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9UsIQiYASdC"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(35),\n",
        "    #tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2,),\n",
        "    tf.keras.layers.experimental.preprocessing.Rescaling(scale=1./255)])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_A7ezFTATIR",
        "outputId": "4edb6ea2-77f9-4579-df40-dbf5b45b182a"
      },
      "source": [
        "train_aug_ds = parsed_image_dataset.filter(lambda x,y: tf.math.not_equal(y,3))\n",
        "val_aug_ds = val_image_dataset.filter(lambda x,y: tf.math.not_equal(y,3))\n",
        "train_aug_ds = train_aug_ds.batch(32)\n",
        "val_aug_ds = val_aug_ds.batch(32)\n",
        "train_aug_ds = train_aug_ds.map(lambda x,y:(data_augmentation(x),y))\n",
        "val_aug_ds = val_aug_ds.map(lambda x,y:(data_augmentation(x),y))\n",
        "for i,x in train_aug_ds.take(1):\n",
        "  print(i.shape)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 512, 512, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZGyaACkbOHv"
      },
      "source": [
        "aug_train_ds =train_aug_ds.unbatch()\n",
        "aug_val_ds = val_aug_ds.unbatch()\n",
        "parsed_image_dataset = parsed_image_dataset.concatenate(aug_train_ds)\n",
        "val_image_dataset = val_image_dataset.concatenate(aug_val_ds)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r69P3MUDk-Ea"
      },
      "source": [
        "def create_dataset(dataset):    \n",
        "    # Set the number of datapoints you want to load and shuffle \n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    # Set the batchsize\n",
        "    dataset = dataset.batch(64)\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADqnIjkdeFkz"
      },
      "source": [
        "train_dataset = create_dataset(parsed_image_dataset)\n",
        "validation_dataset = create_dataset(val_image_dataset)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP00kRXTxyDA"
      },
      "source": [
        "# Preprocessing - Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IebVtM6PxyDA"
      },
      "source": [
        "datagen_train = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
        "      horizontal_flip=True,\n",
        "      #width_shift_range=0.2, height_shift_range=0.2,\n",
        "      shear_range=0.2, \n",
        "      zoom_range=0.3,\n",
        "      rescale=1./255, validation_split=.1,\n",
        "      )\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "    train_dataset., shuffle=True,subset='training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5xUGY9qxyDB"
      },
      "source": [
        "datagen_val = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    #rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      #width_shift_range=0.2, height_shift_range=0.2,\n",
        "      #shear_range=0.2, zoom_range=0.2,\n",
        "      rescale=1./255, validation_split=.1,\n",
        "      )\n",
        "val_generator = datagen_val.NumpyArrayIterator(\n",
        "    TRAIN_IMAGE_DIRECTORY,target_size=(256,256), shuffle=True,subset='validation',class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0kvwDD1xyDB"
      },
      "source": [
        "# Model - Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdIzzEHiQla5"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(35),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomZoom(\n",
        "    height_factor=0.2,),\n",
        "    tf.keras.layers.experimental.preprocessing.Rescaling(scale=1./255\n",
        "    )\n",
        "  \n",
        "])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuIBqEi3Xqnz"
      },
      "source": [
        "### Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHQRQbU_xyDB"
      },
      "source": [
        "with strategy.scope():\n",
        "    base = tf.keras.applications.ResNet50V2(include_top=False,input_shape=(*IMAGE_SIZE,3),weights=None)\n",
        "    base.trainable = True\n",
        "    inputs = tf.keras.layers.Input([*IMAGE_SIZE, 3])\n",
        "    pre_layer = tf.keras.applications.resnet50.preprocess_input(inputs)#.get_layer()\n",
        "    base_layer = base(pre_layer)\n",
        "    base_model = tf.keras.layers.Dense(512,activation='relu',kernel_regularizer=tf.keras.regularizers.l2())(base_model)\n",
        "    base_model = tf.keras.layers.Dense(256,activation='relu',kernel_regularizer=tf.keras.regularizers.l2())(base_model)\n",
        "    \"\"\"base_model = tf.keras.layers.BatchNormalization()(base_model)\n",
        "    base_model = tf.keras.layers.Dense(64,activation='relu',)(base_model)\n",
        "    base_model = tf.keras.layers.Dense(32,activation='relu',)(base_model)\"\"\"\n",
        "    base_model = tf.keras.layers.GlobalAveragePooling2D()(base_model)\n",
        "    base_model = tf.keras.layers.BatchNormalization()(base_model)\n",
        "    base_model = tf.keras.layers.Dense(256,activation='relu',kernel_regularizer=tf.keras.regularizers.l2())(base_model)\n",
        "    base_model = tf.keras.layers.Dense(128,activation='relu',)(base_model)\n",
        "    base_model = tf.keras.layers.Dense(64,activation='relu',)(base_model)\n",
        "    base_model = tf.keras.layers.Dense(32,activation='relu',)(base_model)\n",
        "    base_model = tf.keras.layers.Dense(8,activation='relu',)(base_model)\n",
        "    base_model = tf.keras.layers.Dropout(0.2)(base_model)\n",
        "    base_model = tf.keras.layers.Dense(5,activation='softmax')(base_model)\n",
        "    \n",
        "    model_res = tf.keras.Model(inputs=inputs,outputs=base_model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVDIFZy1xyDF"
      },
      "source": [
        "model_res.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbpJMLYbEwMn"
      },
      "source": [
        "model_res.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=lr_schedule),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzyU31ngxyDF"
      },
      "source": [
        "epochs=25\n",
        "history = model_res.fit(\n",
        "  train_dataset,\n",
        "  epochs=epochs,\n",
        "  validation_data = validation_dataset,\n",
        "  callbacks=[checkpoint_cb, early_stopping_cb]\n",
        "  #class_weight = cl_w\n",
        "  #steps_per_epoch = 600\n",
        "  #validation_data = val_generator,\n",
        "\n",
        " \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGIOT5hjXttb"
      },
      "source": [
        "### Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWYxHOVU7X2f",
        "outputId": "0f5ef50a-7199-47a2-9435-879a612d4794"
      },
      "source": [
        "with strategy.scope():\n",
        "    base = tf.keras.applications.EfficientNetB5(include_top=False,input_shape=(*IMAGE_SIZE,3),\n",
        "                                                weights='imagenet')\n",
        "    base.trainable = False\n",
        "    inputs = tf.keras.layers.Input([*IMAGE_SIZE, 3])\n",
        "    pre_layer = tf.keras.applications.efficientnet.preprocess_input(inputs)#.get_layer(\n",
        "    base_model = base(pre_layer)\n",
        "    base_model = tf.keras.layers.Dense(1024,activation='relu',kernel_regularizer=tf.keras.regularizers.l2())(base_model)\n",
        "    base_model = tf.keras.layers.Dense(512,activation='relu',kernel_regularizer=tf.keras.regularizers.l2())(base_model)\n",
        "    base_model = tf.keras.layers.Dense(256,activation='relu',kernel_regularizer=tf.keras.regularizers.l2())(base_model)\n",
        "    base_model = tf.keras.layers.BatchNormalization()(base_model)\n",
        "    base_model = tf.keras.layers.Flatten()(base_model)\n",
        "    base_model = tf.keras.layers.Dense(512,activation='relu',kernel_regularizer=tf.keras.regularizers.l2())(base_model)\n",
        "    base_model = tf.keras.layers.Dense(256,activation='relu',kernel_regularizer=tf.keras.regularizers.l2())(base_model)\n",
        "    base_model = tf.keras.layers.Dense(128,activation='relu')(base_model)\n",
        "    base_model = tf.keras.layers.Dense(64,activation='relu',)(base_model)\n",
        "    base_model = tf.keras.layers.Dense(32,activation='relu',)(base_model)\n",
        "    base_model = tf.keras.layers.Dense(8,activation='relu',)(base_model)\n",
        "    base_model = tf.keras.layers.Dropout(0.2)(base_model)\n",
        "    base_model = tf.keras.layers.Dense(5,activation='softmax')(base_model)\n",
        "    \n",
        "    model_custom = tf.keras.Model(inputs=inputs,outputs=base_model)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n",
            "115269632/115263384 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJAF4pY1iW0D"
      },
      "source": [
        "initial_learning_rate = 0.001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=100, decay_rate=0.96, staircase=True\n",
        ")\n",
        "\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"best_model.h5\", save_best_only=True\n",
        ")\n",
        "\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10, restore_best_weights=True\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahawYSqJcpoK",
        "outputId": "e5a71bcd-3127-43fb-8641-bb96e2f947e7"
      },
      "source": [
        "model_custom.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
            "_________________________________________________________________\n",
            "efficientnetb5 (Functional)  (None, 16, 16, 2048)      28513527  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16, 16, 1024)      2098176   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16, 16, 512)       524800    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16, 16, 256)       131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               33554944  \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 264       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 45        \n",
            "=================================================================\n",
            "Total params: 64,998,668\n",
            "Trainable params: 36,484,629\n",
            "Non-trainable params: 28,514,039\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMX_PVhl7owa"
      },
      "source": [
        "model_custom.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az5qMxjo7rb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d1a14dd-44de-46ac-854e-12bc138a8308"
      },
      "source": [
        "epochs=10\n",
        "history = model_custom.fit(\n",
        "  train_dataset,\n",
        "  epochs=epochs,\n",
        "  validation_data = validation_dataset,\n",
        "  callbacks=[checkpoint_cb, early_stopping_cb]\n",
        "  #class_weight = cl_w\n",
        "  #steps_per_epoch = 600\n",
        "  #validation_data = val_generator,\n",
        "\n",
        " \n",
        ")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "406/406 [==============================] - 100s 245ms/step - loss: 1.3427 - accuracy: 0.6294 - val_loss: 1.1872 - val_accuracy: 0.6454\n",
            "Epoch 2/10\n",
            "406/406 [==============================] - 100s 245ms/step - loss: 1.2029 - accuracy: 0.6317 - val_loss: 1.1439 - val_accuracy: 0.6408\n",
            "Epoch 3/10\n",
            "406/406 [==============================] - 99s 244ms/step - loss: 1.1173 - accuracy: 0.6354 - val_loss: 1.0373 - val_accuracy: 0.6473\n",
            "Epoch 4/10\n",
            "406/406 [==============================] - 99s 245ms/step - loss: 1.0603 - accuracy: 0.6402 - val_loss: 0.9725 - val_accuracy: 0.6549\n",
            "Epoch 5/10\n",
            "406/406 [==============================] - 90s 221ms/step - loss: 1.0225 - accuracy: 0.6470 - val_loss: 0.9877 - val_accuracy: 0.6508\n",
            "Epoch 6/10\n",
            "406/406 [==============================] - 100s 247ms/step - loss: 0.9946 - accuracy: 0.6467 - val_loss: 0.9414 - val_accuracy: 0.6470\n",
            "Epoch 7/10\n",
            "406/406 [==============================] - 100s 247ms/step - loss: 0.9696 - accuracy: 0.6479 - val_loss: 0.9206 - val_accuracy: 0.6581\n",
            "Epoch 8/10\n",
            "406/406 [==============================] - 91s 224ms/step - loss: 0.9538 - accuracy: 0.6521 - val_loss: 0.9532 - val_accuracy: 0.6551\n",
            "Epoch 9/10\n",
            "406/406 [==============================] - 90s 222ms/step - loss: 0.9466 - accuracy: 0.6526 - val_loss: 0.9292 - val_accuracy: 0.6659\n",
            "Epoch 10/10\n",
            "406/406 [==============================] - 101s 249ms/step - loss: 0.9319 - accuracy: 0.6555 - val_loss: 0.8831 - val_accuracy: 0.6819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PDgrRpgsNZn"
      },
      "source": [
        "model_custom.optimizer._decayed_lr(tf.float32).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6sQPv5uwn9O"
      },
      "source": [
        "model_custom.save('effecienetcustom_B4_model.h5')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyfO3ytCr1_n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH-4SG4fxyDF"
      },
      "source": [
        "prediction,test_data = submit_gen(model_custom,\n",
        "                                  classes=sorted(train_records.label.unique()),\n",
        "                                  dataset_path='/content/test/')"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onez_SdmxyDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7dcda8c-af0c-41e6-e9d7-9c6b49aad91d"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2216849948.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUWWuRp6xyDF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "c59b3edc-98e3-4b74-87a0-3ef1016fb66b"
      },
      "source": [
        "submission = pd.DataFrame({\"image_id\":np.squeeze(test_data),\"label\":prediction})\n",
        "submission.head()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2216849948.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_id  label\n",
              "0  2216849948.jpg      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noB1fgOuxyDF"
      },
      "source": [
        "submission.to_csv('submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz32MGURxyDF"
      },
      "source": [
        "model_res.save('initial_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz7Zu4Y0xyDF"
      },
      "source": [
        "!rm -R ./data_train"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}